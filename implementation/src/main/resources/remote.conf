akka {
  actor {
    provider = cluster
    serializers {
      java = "akka.serialization.JavaSerializer"
      kryo = "com.twitter.chill.akka.ConfiguredAkkaSerializer"
    }
    serialization-bindings {
      "java.io.Serializable" = kryo
      "de.hpi.rdse.jujo.actors.slave.CorpusReceiver$ProcessCorpusPartition" = java
      "de.hpi.rdse.jujo.actors.master.training.ResultPartitionReceiver$ProcessResults" = java
      "de.hpi.rdse.jujo.actors.common.VocabularyReceiver$ProcessVocabulary" = java
      "akka.stream.impl.streamref.StreamRefsProtocol$CumulativeDemand" = java
      "akka.stream.impl.streamref.StreamRefsProtocol$OnSubscribeHandshake" = java
      "akka.stream.impl.streamref.StreamRefsProtocol$RemoteStreamFailure" = java
      "akka.stream.impl.streamref.StreamRefsProtocol$SequencedOnNext" = java
      "akka.stream.impl.streamref.StreamRefsProtocol$RemoteStreamCompleted" = java
      "akka.cluster.metrics.ClusterMetricsChanged" = java
    }
  }
  remote {
    enabled-transports = ["akka.remote.netty.tcp"]
    maximum-payload-bytes = 3000000 bytes
    netty.tcp {
      // The $variables are no standard syntax. We replace them manually (see AkkaUtils).
      hostname = "$host"
      port = $port
      message-frame-size =  3000000b
      send-buffer-size =  3000000b
      receive-buffer-size =  3000000b
      maximum-frame-size = 3000000b
    }
  }
}

# Enable metrics extension in akka-cluster-metrics.
akka.extensions = ["akka.cluster.metrics.ClusterMetricsExtension"]

akka.cluster.metrics {
  # Metrics collector actor.
  collector {
    # Enable or disable metrics collector for load-balancing nodes.
    # Metrics collection can also be controlled at runtime by sending control messages
    # to /system/cluster-metrics actor: `akka.cluster.metrics.{CollectionStartMessage,CollectionStopMessage}`
    enabled = on
    # FQCN of the metrics collector implementation.
    # It must implement `akka.cluster.metrics.MetricsCollector` and
    # have public constructor with akka.actor.ActorSystem parameter.
    # Will try to load in the following order of priority:
    # 1) configured custom collector 2) internal `SigarMetricsCollector` 3) internal `JmxMetricsCollector`
    provider = ""
    # Try all 3 available collector providers, or else fail on the configured custom collector provider.
    fallback = true
    # How often metrics are sampled on a node.
    # Shorter interval will collect the metrics more often.
    # Also controls frequency of the metrics publication to the node system event bus.
    sample-interval = 30s
    # How often a node publishes metrics information to the other nodes in the cluster.
    # Shorter interval will publish the metrics gossip more often.
    gossip-interval = 30s
    # How quickly the exponential weighting of past data is decayed compared to
    # new data. Set lower to increase the bias toward newer values.
    # The relevance of each data sample is halved for every passing half-life
    # duration, i.e. after 4 times the half-life, a data sample’s relevance is
    # reduced to 6% of its original relevance. The initial relevance of a data
    # sample is given by 1 – 0.5 ^ (collect-interval / half-life).
    moving-average-half-life = 12s
  }
}
